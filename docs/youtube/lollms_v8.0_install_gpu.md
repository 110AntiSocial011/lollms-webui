Hi there,

In this short I'm going to show you how to install lollms in GPU mode and use the hugging face binding to run inference.

The steps to aceive this are simple:
download the installer from the github of the project to an empty folder with a path that does not contain spaces.
double click the installer and validate.
select the install mode (Cuda, rocm or cpu)
wait
Run the app
Choose the personal data folder
Install a binding
Reboot the app
Select the binding
Install a model
Select a model


Start by opening the lollms web user interface link that you can find in the description. Then go to the latest release page and download the 